{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-72e1445b5041>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           image     category\n",
      "0  0050f38b3.png  Black-grass\n",
      "1  0183fdf68.png  Black-grass\n",
      "2  0260cffa8.png  Black-grass\n",
      "3  05eedce4d.png  Black-grass\n",
      "4  075d004bc.png  Black-grass\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import keras\n",
    "# from keras.models import Sequential,Input,Model\n",
    "# from keras.layers import Dense, Dropout, Flatten\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "import scipy.misc\n",
    "from skimage import transform\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#convertering list of training data paths to df\n",
    "train_dir = 'C:/Users/Administrator/Downloads/all/train/train/'\n",
    "train_list = os.listdir(train_dir)\n",
    "records = []\n",
    "for category in train_list:\n",
    "    img_list = os.listdir(train_dir + category)\n",
    "    for img in img_list:\n",
    "        records.append((img,category))\n",
    "        \n",
    "df_train = pd.DataFrame.from_records(records,columns=['image','category'])\n",
    "\n",
    "print(df_train.head())\n",
    "\n",
    "\n",
    "\n",
    "# #looking at the test data\n",
    "# test_dir = '../input/test/'\n",
    "# test_list = os.listdir(test_dir)\n",
    "# print('Train Data', len(df_train.index))\n",
    "# print('Test Data',type(test_list),len(test_list))\n",
    "# print('categories',os.listdir(train_dir))\n",
    "# print('# of categories', len(os.listdir(train_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADsVJREFUeJzt3X+oZGd9x/H3p0kVaoXEZhMkyXZjWAVT2lu9WEGUWKvGUFxT0O5SdGtDN0ICLfSPJhaq9C9pTQPSGklwSQRNTJtG88dWDaEohaZmV9OYqNFNXM1ml901FpVGlN18+8eci/Ps3pt7986ZH3fu+wWXmXnmzJzn2bnz2fOcc+75pqqQpCW/Mu0OSJothoKkhqEgqWEoSGoYCpIahoKkxthCIclVSZ5IcjDJjeNaj6R+ZRznKSQ5B/gO8FbgMPAwsKuqvtn7yiT1alxbCq8DDlbVU1X1C+BuYMeY1iWpR+eO6X0vBp4eenwY+L2VFr7gggtq27ZtY+qKJIADBw78sKq2rLbcuEIhy7Q185Qke4A9AFu3bmX//v1j6ookgCTfX8ty45o+HAYuHXp8CXBkeIGquq2qFqtqccuWVcNL0oSMKxQeBrYnuSzJi4CdwP1jWpekHo1l+lBVJ5PcAHwROAfYW1WPj2Ndkvo1rn0KVNU+YN+43l/SeHhGo6SGoSCpYShIahgKkhqGgqSGoSBNzHIn+s4eQ0GamI1x5XRDQVLDUJDUMBQkNQwFzZiNsTNunhkKmjEbY2fcPDMUJDUMBUkNQ0FSw1CQ1DAUtE6hvyMFHnGYJYaC1qnPowQecZglhoJG4Jd5Hq07FJJcmuQ/knwryeNJ/qJr/3CSZ5I80v1c3V93JY3bKBduPQn8VVV9LclLgQNJHuieu6WqPjp69yRN2rpDoaqOAke7+z9N8i0G5eIkbWC97FNIsg34XeC/u6YbkjyaZG+S8/tYh6TJGDkUkvw6cC/wl1X1E+BW4HJggcGWxM0rvG5Pkv1J9p84cWLUbkjqyUihkORXGQTCp6vq3wCq6lhVnaqq54HbGZSlP4O1JKXZNMrRhwCfBL5VVf841P7yocWuAR5bf/dmTZ8n7EizaZSjD28A3gt8I8kjXdsHgV1JFhgcxD4EXDdSD2dCGAynMBQ070Y5+vCfLP8NmbP6kacP0RN2NN/GVmB2Moa/sH1+WZe2DPp+X2n2eZqzpMYG31Lo+3/xpS0Ptw60eW3wUOibYSBtsumDRw6k1WyyUHBLQFrNJgsFSasxFCQ1DAVJDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFDRjPBV92vyDKOmsjes6HrPBLQXNmI3wJVu6NN98MhSkdZvPYBh5+pDkEPBT4BRwsqoWk7wM+CywjcHFW99TVf876ro0LsOXn9PqJnExnul9Jn1tKby5qhaqarF7fCPwYFVtBx7sHo+Bl1zvh4FwdiYxfZjeZzKu6cMO4M7u/p3Au8a0Hkk96yMUCvhSkgNJ9nRtF3UFaJcK0V54+ossGyfNpj4OSb6hqo4kuRB4IMm31/KiqroNuA1gcXGxh20l58Xzzc93UkbeUqiqI93tceA+BrUjjy2Vj+tuj4+6nhXWTlufwf0LmhOZ3u/yqAVmX5LkpUv3gbcxqB15P7C7W2w38PlR1rN2/k+yNtP4hRt1nZvss63pjXfU6cNFwH2DWrOcC3ymqr6Q5GHgniTXAj8A3j3ietSrafzCbbIv9QY2UihU1VPA7yzT/izwllHeWxuFc/154xmNGpGBMG8MBUkNQ0FSw1DQnBnHkZXNdajbUJBWtbn2mxgKmjPdFzj+sdx6eeUlzacpnvyz0bmloE3ILYgXYihoE3Ir4oUYCpIahoKkhqEgqWEoSGoYCpIahoKkhqEgzat1no5hKEjjNq3rLa7zdAxDQRq3DXbK9br/9iHJqxiUhlvyCuBvgfOAPweWijl8sKr2rbuHkiZq3aFQVU8ACwBJzgGeYXCJ9/cDt1TVR3vpoaSJ6mv68Bbgyar6fk/vJ53GP2KalL5CYSdw19DjG5I8mmRvkvN7Woc2tY01L9/IRg6FJC8C3gn8S9d0K3A5g6nFUeDmFV5nLUlpBvWxpfAO4GtVdQygqo5V1amqeh64nUEZuTNU1W1VtVhVi1u2bOmhG5L60Eco7GJo6rBUQ7JzDYMycmvkvHFlXl5MkzHS5diS/BrwVuC6oea/T7LAYBJ46LTnJM24UcvGPQf8xmlt7x2pR1rGPJRmm4cxjGLK4z+LjcwZO6NxM//SvJAZ+3dZ7rTdZIXTeZfaZmwM47Tsv8UUxj884zyL1Xs1Z5295U7bXfFU3hXakw13+u+azcq4/NuHzWQOdjjOyhdHZzAUNiS/UBofQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDXWFApdUZfjSR4bantZkgeSfLe7Pb9rT5KPJTnYFYR5zbg6L6l/a91SuAO46rS2G4EHq2o78GD3GAZ1ILZ3P3sYFIeRtEGsKRSq6ivAj05r3gHc2d2/E3jXUPunauAh4LzTakFImmGj7FO4qKqOAnS3F3btFwNPDy13uGuTtAGMY0fjclcVPeOigtaSlGbTKKFwbGla0N0e79oPA5cOLXcJcOT0F1tLUppNo4TC/cDu7v5u4PND7e/rjkK8Hvjx0jRD0uxbUzGYJHcBVwIXJDkMfAj4CHBPkmuBHwDv7hbfB1wNHASeA97fc58ljdGaQqGqdq3w1FuWWbaA60fplKTp8YxGSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUWDUUVqgj+Q9Jvt3VirwvyXld+7YkP0vySPfziXF2XlL/1rKlcAdn1pF8APitqvpt4DvATUPPPVlVC93PB/rppqRJWTUUlqsjWVVfqqqT3cOHGBR8kTQH+tin8GfAvw89vizJ15N8Ockbe3h/SRO0proPK0nyN8BJ4NNd01Fga1U9m+S1wOeSXFFVP1nmtXsYlKpn69ato3RDUo/WvaWQZDfwh8CfdAVgqKqfV9Wz3f0DwJPAK5d7vbUkpdm0rlBIchXw18A7q+q5ofYtSc7p7r8C2A481UdHJU3GqtOHFepI3gS8GHggCcBD3ZGGNwF/l+QkcAr4QFX9aNk3ljSTVg2FFepIfnKFZe8F7h21U5KmxzMaJTUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSY721JD+c5JmhmpFXDz13U5KDSZ5I8vZxdVzSeKy3liTALUM1I/cBJHk1sBO4onvNx5cu+S5pY1hXLckXsAO4uysK8z3gIPC6EfonacJG2adwQ1eKfm+S87u2i4Gnh5Y53LWdIcmeJPuT7D9x4sQI3ZDUp/WGwq3A5cACg/qRN3ftWWbZWu4NLBsnzaZ1hUJVHauqU1X1PHA7v5wiHAYuHVr0EuDIaF2UNEnrrSX58qGH1wBLRybuB3YmeXGSyxjUkvzqaF2UNEnrrSV5ZZIFBlODQ8B1AFX1eJJ7gG8yKFF/fVWdGk/XJY1DuiryU7W4uFj79++fdjekuZbkQFUtrracZzRKahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhrrLRv32aGScYeSPNK1b0vys6HnPjHOzkvq36oXbmVQNu6fgE8tNVTVHy/dT3Iz8OOh5Z+sqoW+OihpslYNhar6SpJtyz2XJMB7gN/vt1uSpmXUfQpvBI5V1XeH2i5L8vUkX07yxhHfX9KErWX68EJ2AXcNPT4KbK2qZ5O8Fvhckiuq6ienvzDJHmAPwNatW0fshqS+rHtLIcm5wB8Bn11q66pNP9vdPwA8CbxyuddbS1KaTaNMH/4A+HZVHV5qSLIlyTnd/VcwKBv31GhdlDRJazkkeRfwX8CrkhxOcm331E7aqQPAm4BHk/wP8K/AB6rqR312WNJ4reXow64V2v90mbZ7gXtH75akafGMRkkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSI1U17T6Q5ATwf8APp92XMbmA+R0bzPf45mlsv1lVq146fSZCASDJ/qpanHY/xmGexwbzPb55HttKnD5IahgKkhqzFAq3TbsDYzTPY4P5Ht88j21ZM7NPQdJsmKUtBUkzYOqhkOSqJE8kOZjkxmn3pw9JDiX5RpJHkuzv2l6W5IEk3+1uz592P9cqyd4kx5M8NtS27Hgy8LHu83w0yWum1/PVrTC2Dyd5pvv8Hkly9dBzN3VjeyLJ26fT6/Gaaih0xWj/GXgH8GpgV5JXT7NPPXpzVS0MHc66EXiwqrYDD3aPN4o7gKtOa1tpPO9gUFh4O7AHuHVCfVyvOzhzbAC3dJ/fQlXtA+h+N3cCV3Sv+fhSQeV5Mu0thdcBB6vqqar6BXA3sGPKfRqXHcCd3f07gXdNsS9npaq+ApxeKHil8ewAPlUDDwHnJXn5ZHp69lYY20p2AHdX1c+r6nvAQQa/w3Nl2qFwMfD00OPDXdtGV8CXkhxIsqdru6iqjgJ0txdOrXf9WGk88/KZ3tBNf/YOTfXmZWwvaNqhkGXa5uFwyBuq6jUMNqWvT/KmaXdogubhM70VuBxYAI4CN3ft8zC2VU07FA4Dlw49vgQ4MqW+9KaqjnS3x4H7GGxiHlvajO5uj0+vh71YaTwb/jOtqmNVdaqqngdu55dThA0/trWYdig8DGxPclmSFzHYiXP/lPs0kiQvSfLSpfvA24DHGIxrd7fYbuDz0+lhb1Yaz/3A+7qjEK8Hfrw0zdgoTtsHcg2Dzw8GY9uZ5MVJLmOwM/Wrk+7fuJ07zZVX1ckkNwBfBM4B9lbV49PsUw8uAu5LAoN/389U1ReSPAzck+Ra4AfAu6fYx7OS5C7gSuCCJIeBDwEfYfnx7AOuZrAT7jng/RPv8FlYYWxXJllgMDU4BFwHUFWPJ7kH+CZwEri+qk5No9/j5BmNkhrTnj5ImjGGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIavw/0XMb/vZ8qrgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what our images look like.\n",
    "for i in list(df_train['image'])[0:1]:\n",
    "    img = Image.open(train_dir + df_train['category'][0] + '/' + i)\n",
    "    img.load()\n",
    "    data = np.asarray(img, dtype=\"float32\" )\n",
    "    plt.imshow(data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will normalize our images and remove any images that possibly aren't square. \n",
    "# Then we will create our X and y datasets.\n",
    "dim_image = []\n",
    "for i in (train_dir + df_train['category'] + '/' + df_train['image']):\n",
    "    img = Image.open(i)\n",
    "    data = img.size\n",
    "    dim_image.append(data[0])\n",
    "print('smallest image dimension', min(dim_image))\n",
    "\n",
    "i_height = min(dim_image)\n",
    "i_width = min(dim_image)\n",
    "\n",
    "X = []\n",
    "count = 0\n",
    "bad_images = []\n",
    "#df_train = df_train.drop(df_train.index[bad_images])\n",
    "for i in (train_dir + df_train['category'] + '/' + df_train['image']):\n",
    "    img = Image.open(i)\n",
    "    img.load()\n",
    "    img = np.asarray(img, dtype='float32')\n",
    "    img = img/255\n",
    "    data = transform.resize(img,(49,49))\n",
    "    if data.size != 7203:\n",
    "        bad_images.append(count)\n",
    "#     plt.imshow(data)\n",
    "#     plt.show()\n",
    "#     X.append(data)\n",
    "    count += 1\n",
    "print('bad images',bad_images)\n",
    "\n",
    "df_train = df_train.drop(df_train.index[bad_images])\n",
    "for i in (train_dir + df_train['category'] + '/' + df_train['image']):\n",
    "    img = Image.open(i)\n",
    "    img.load()\n",
    "    img = np.asarray(img, dtype='float32')\n",
    "    img = img/255\n",
    "    data = transform.resize(img,(49,49))\n",
    "    X.append(data)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "y = np.array(df_train['category'].astype('category').cat.codes)\n",
    "\n",
    "print('Done creating X and y.')\n",
    "print('X Shape',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "im_shape = (49,49,3)\n",
    "batch_size = 10\n",
    "\n",
    "cnn  = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), activation='linear', input_shape=im_shape, padding='same'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPooling2D((2,2), padding='same'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='linear', padding='same'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPooling2D((2,2), padding='same'),\n",
    "    Conv2D(128, kernel_size=(3,3), activation='linear', padding='same'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPooling2D((2,2), padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(50,activation='relu'),\n",
    "    Dense(12, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "cnn. fit(X_train, y_train, batch_size=batch_size, epochs=10, verbose=1, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy 97%\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Maximum\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize as imresize\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "RANDOM_STATE = 11\n",
    "\n",
    "CLASS = {\n",
    "    'Black-grass': 0,\n",
    "    'Charlock': 1,\n",
    "    'Cleavers': 2,\n",
    "    'Common Chickweed': 3,\n",
    "    'Common wheat': 4,\n",
    "    'Fat Hen': 5,\n",
    "    'Loose Silky-bent': 6,\n",
    "    'Maize': 7,\n",
    "    'Scentless Mayweed': 8,\n",
    "    'Shepherds Purse': 9,\n",
    "    'Small-flowered Cranesbill': 10,\n",
    "    'Sugar beet': 11\n",
    "}\n",
    "\n",
    "INV_CLASS = {\n",
    "    0: 'Black-grass',\n",
    "    1: 'Charlock',\n",
    "    2: 'Cleavers',\n",
    "    3: 'Common Chickweed',\n",
    "    4: 'Common wheat',\n",
    "    5: 'Fat Hen',\n",
    "    6: 'Loose Silky-bent',\n",
    "    7: 'Maize',\n",
    "    8: 'Scentless Mayweed',\n",
    "    9: 'Shepherds Purse',\n",
    "    10: 'Small-flowered Cranesbill',\n",
    "    11: 'Sugar beet'\n",
    "}\n",
    "\n",
    "# Dense layers set\n",
    "def dense_set(inp_layer, n, activation, drop_rate=0.):\n",
    "    dp = Dropout(drop_rate)(inp_layer)\n",
    "    dns = Dense(n)(dp)\n",
    "    bn = BatchNormalization(axis=-1)(dns)\n",
    "    act = Activation(activation=activation)(bn)\n",
    "    return act\n",
    "\n",
    "# Conv. layers set\n",
    "def conv_layer(feature_batch, feature_map, kernel_size=(3, 3),strides=(1,1), zp_flag=False):\n",
    "    if zp_flag:\n",
    "        zp = ZeroPadding2D((1,1))(feature_batch)\n",
    "    else:\n",
    "        zp = feature_batch\n",
    "    conv = Conv2D(filters=feature_map, kernel_size=kernel_size, strides=strides)(zp)\n",
    "    bn = BatchNormalization(axis=3)(conv)\n",
    "    act = LeakyReLU(1/10)(bn)\n",
    "    return act\n",
    "\n",
    "# simple model \n",
    "def get_model():\n",
    "    inp_img = Input(shape=(51, 51, 3))\n",
    "\n",
    "    # 51\n",
    "    conv1 = conv_layer(inp_img, 64, zp_flag=False)\n",
    "    conv2 = conv_layer(conv1, 64, zp_flag=False)\n",
    "    mp1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv2)\n",
    "    # 23\n",
    "    conv3 = conv_layer(mp1, 128, zp_flag=False)\n",
    "    conv4 = conv_layer(conv3, 128, zp_flag=False)\n",
    "    mp2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv4)\n",
    "    # 9\n",
    "    conv7 = conv_layer(mp2, 256, zp_flag=False)\n",
    "    conv8 = conv_layer(conv7, 256, zp_flag=False)\n",
    "    conv9 = conv_layer(conv8, 256, zp_flag=False)\n",
    "    mp3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv9)\n",
    "    # 1\n",
    "    # dense layers\n",
    "    flt = Flatten()(mp3)\n",
    "    ds1 = dense_set(flt, 128, activation='tanh')\n",
    "    out = dense_set(ds1, 12, activation='softmax')\n",
    "\n",
    "    model = Model(inputs=inp_img, outputs=out)\n",
    "    \n",
    "    # The first 50 epochs are used by Adam opt.\n",
    "    # Then 30 epochs are used by SGD opt.\n",
    "    \n",
    "    #mypotim = Adam(lr=2 * 1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    mypotim = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=mypotim,\n",
    "                   metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_callbacks(filepath, patience=5):\n",
    "    lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=1e-5, patience=patience, verbose=1)\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [lr_reduce, msave]\n",
    "\n",
    "# I trained model about 12h on GTX 950.\n",
    "def train_model(img, target):\n",
    "    callbacks = get_callbacks(filepath='model_weight_SGD.hdf5', patience=6)\n",
    "    gmodel = get_model()\n",
    "    gmodel.load_weights(filepath='model_weight_Adam.hdf5')\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "                                                        img,\n",
    "                                                        target,\n",
    "                                                        shuffle=True,\n",
    "                                                        train_size=0.8,\n",
    "                                                        random_state=RANDOM_STATE\n",
    "                                                        )\n",
    "    gen = ImageDataGenerator(\n",
    "            rotation_range=360.,\n",
    "            width_shift_range=0.3,\n",
    "            height_shift_range=0.3,\n",
    "            zoom_range=0.3,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "    )\n",
    "    gmodel.fit_generator(gen.flow(x_train, y_train,batch_size=BATCH_SIZE),\n",
    "               steps_per_epoch=10*len(x_train)/BATCH_SIZE,\n",
    "               epochs=EPOCHS,\n",
    "               verbose=1,\n",
    "               shuffle=True,\n",
    "               validation_data=(x_valid, y_valid),\n",
    "               callbacks=callbacks)\n",
    "\n",
    "def test_model(img, label):\n",
    "    gmodel = get_model()\n",
    "    gmodel.load_weights(filepath='../input/plant-weight/model_weight_SGD.hdf5')\n",
    "    prob = gmodel.predict(img, verbose=1)\n",
    "    pred = prob.argmax(axis=-1)\n",
    "    sub = pd.DataFrame({\"file\": label,\n",
    "                         \"species\": [INV_CLASS[p] for p in pred]})\n",
    "    sub.to_csv(\"sub.csv\", index=False, header=True)\n",
    "\n",
    "# Resize all image to 51x51 \n",
    "def img_reshape(img):\n",
    "    img = imresize(img, (51, 51, 3))\n",
    "    return img\n",
    "\n",
    "# get image tag\n",
    "def img_label(path):\n",
    "    return str(str(path.split('/')[-1]))\n",
    "\n",
    "# get plant class on image\n",
    "def img_class(path):\n",
    "    return str(path.split('/')[-2])\n",
    "\n",
    "# fill train and test dict\n",
    "def fill_dict(paths, some_dict):\n",
    "    text = ''\n",
    "    if 'train' in paths[0]:\n",
    "        text = 'Start fill train_dict'\n",
    "    elif 'test' in paths[0]:\n",
    "        text = 'Start fill test_dict'\n",
    "\n",
    "    for p in tqdm(paths, ascii=True, ncols=85, desc=text):\n",
    "        img = imageio.imread(p)\n",
    "        img = img_reshape(img)\n",
    "        some_dict['image'].append(img)\n",
    "        some_dict['label'].append(img_label(p))\n",
    "        if 'train' in paths[0]:\n",
    "            some_dict['class'].append(img_class(p))\n",
    "\n",
    "    return some_dict\n",
    "\n",
    "# read image from dir. and fill train and test dict\n",
    "def reader():\n",
    "    file_ext = []\n",
    "    train_path = []\n",
    "    test_path = []\n",
    "\n",
    "    for root, dirs, files in os.walk('../input'):\n",
    "        if dirs != []:\n",
    "            print('Root:\\n'+str(root))\n",
    "            print('Dirs:\\n'+str(dirs))\n",
    "        else:\n",
    "            for f in files:\n",
    "                ext = os.path.splitext(str(f))[1][1:]\n",
    "\n",
    "                if ext not in file_ext:\n",
    "                    file_ext.append(ext)\n",
    "\n",
    "                if 'train' in root:\n",
    "                    path = os.path.join(root, f)\n",
    "                    train_path.append(path)\n",
    "                elif 'test' in root:\n",
    "                    path = os.path.join(root, f)\n",
    "                    test_path.append(path)\n",
    "    train_dict = {\n",
    "        'image': [],\n",
    "        'label': [],\n",
    "        'class': []\n",
    "    }\n",
    "    test_dict = {\n",
    "        'image': [],\n",
    "        'label': []\n",
    "    }\n",
    "\n",
    "    #train_dict = fill_dict(train_path, train_dict)\n",
    "    test_dict = fill_dict(test_path, test_dict)\n",
    "    return train_dict, test_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I commented out some of the code for learning the model.\n",
    "def main():\n",
    "    train_dict, test_dict = reader()\n",
    "    #X_train = np.array(train_dict['image'])\n",
    "    #y_train = to_categorical(np.array([CLASS[l] for l in train_dict['class']]))\n",
    "\n",
    "    X_test = np.array(test_dict['image'])\n",
    "    label = test_dict['label']\n",
    "    \n",
    "    # I do not recommend trying to train the model on a kaggle.\n",
    "    #train_model(X_train, y_train)\n",
    "    test_model(X_test, label)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

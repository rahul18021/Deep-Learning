{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from vis_utils import *\n",
    "import random;\n",
    "import math;\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from vis_utils import *\n",
    "import random;\n",
    "import math;\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "data_order = 'th'  # 'th' for Theano, 'tf' for Tensorflow\n",
    "# check the order of data and chose proper data shape to save images\n",
    "if data_order == 'th':\n",
    "    train_shape = (len(train_addrs), 3, 224, 224)\n",
    "    val_shape = (len(val_addrs), 3, 224, 224)\n",
    "    test_shape = (len(test_addrs), 3, 224, 224)\n",
    "elif data_order == 'tf':\n",
    "    train_shape = (len(train_addrs), 224, 224, 3)\n",
    "    val_shape = (len(val_addrs), 224, 224, 3)\n",
    "    test_shape = (len(test_addrs), 224, 224, 3)\n",
    "# open a hdf5 file and create earrays\n",
    "hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "hdf5_file.create_dataset(\"train_img\", train_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"val_img\", val_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"test_img\", test_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "hdf5_file.create_dataset(\"train_labels\", (len(train_addrs),), np.int8)\n",
    "hdf5_file[\"train_labels\"][...] = train_labels\n",
    "hdf5_file.create_dataset(\"val_labels\", (len(val_addrs),), np.int8)\n",
    "hdf5_file[\"val_labels\"][...] = val_labels\n",
    "hdf5_file.create_dataset(\"test_labels\", (len(test_addrs),), np.int8)\n",
    "hdf5_file[\"test_labels\"][...] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a numpy array to save the mean of the images\n",
    "mean = np.zeros(train_shape[1:], np.float32)\n",
    "# loop over train addresses\n",
    "for i in range(len(train_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Train data: {}/{}'.format(i, len(train_addrs)))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = train_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # add any image pre-processing here\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "    # save the image and calculate the mean so far\n",
    "    hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "    mean += img / float(len(train_labels))\n",
    "# loop over validation addresses\n",
    "for i in range(len(val_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Validation data: {}/{}'.format(i, len(val_addrs)))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = val_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # add any image pre-processing here\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "    # save the image\n",
    "    hdf5_file[\"val_img\"][i, ...] = img[None]\n",
    "# loop over test addresses\n",
    "for i in range(len(test_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Test data: {}/{}'.format(i, len(test_addrs)))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = test_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # add any image pre-processing here\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "    # save the image\n",
    "    hdf5_file[\"test_img\"][i, ...] = img[None]\n",
    "# save the mean and close the hdf5 file\n",
    "hdf5_file[\"train_mean\"][...] = mean\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "hdf5_path = 'E:/Object_Detection/HD5/dataset155.hdf5'\n",
    "subtract_mean = False\n",
    "# open the hdf5 file\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "# subtract the training mean\n",
    "if subtract_mean:\n",
    "    mm = hdf5_file[\"train_mean\"][0, ...]\n",
    "    mm = mm[np.newaxis, ...]\n",
    "# Total number of samples\n",
    "data_num = hdf5_file[\"train_img\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 10\n",
    "nb_class = 2\n",
    "# create list of batches to shuffle the data\n",
    "batches_list = list(range(int(ceil(float(data_num) / batch_size))))\n",
    "shuffle(batches_list)\n",
    "# loop over batches\n",
    "for n, i in enumerate(batches_list):\n",
    "    i_s = i * batch_size  # index of the first image in this batch\n",
    "    i_e = min([(i + 1) * batch_size, data_num])  # index of the last image in this batch\n",
    "    # read batch images and remove training mean\n",
    "    images = hdf5_file[\"train_img\"][i_s:i_e, ...]\n",
    "    if subtract_mean:\n",
    "        images -= mm\n",
    "    # read labels and convert to one hot encoding\n",
    "    labels = hdf5_file[\"train_labels\"][i_s:i_e]\n",
    "    labels_one_hot = np.zeros((batch_size, nb_class))\n",
    "    labels_one_hot[np.arange(batch_size), labels] = 1\n",
    "    print (n+1, '/', len(batches_list))\n",
    "    print (labels[0], labels_one_hot[0, :])\n",
    "#     plt.imshow(images[0])\n",
    "#     plt.show()\n",
    "    if n == 5:  # break after 5 batches\n",
    "        break\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py    # HDF5 support\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "fileName = 'E:/Object_Detection/HD5/dataset155.hdf5'\n",
    "file = h5py.File(fileName)\n",
    "xtrainT = torch.from_numpy(np.array(file['train_img'], dtype=np.float32)).float()\n",
    "ytrainT = torch.from_numpy(np.array(file['train_labels'], dtype=np.float32)).float()\n",
    "# for item in f.attrs.keys():\n",
    "#     print(item + \":\", f.attrs[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrainT.shape,ytrainT.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
